{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5323f5d-7631-4640-a69e-75d2debda268",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "Week Seven - Sept 5, 2022\n",
    "\n",
    "... also a breif intro to the [Universal Approximation Theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem)\n",
    "\n",
    "## Chapter 18 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25a0b73-a979-4501-9111-b4ab5c1c2eed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: conda: command not found\n",
      "/bin/bash: conda: command not found\n",
      "/bin/bash: conda: command not found\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Let us first install the scikit-learn packages\n",
    "!conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "!conda install --yes --prefix {sys.prefix} numpy\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b6c3a-9869-4581-bd10-aa39eeec1c1a",
   "metadata": {},
   "source": [
    "## Can we teach a perceptron some basic 'AND' boolean logic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b38a2-b435-4eb8-9804-9e2b49e4675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "X1_train = []\n",
    "y1_train = []\n",
    "X1_test  = []\n",
    "y1_test  = []\n",
    "\n",
    "print(\"Building Training data...\")\n",
    "for i in range(100):                    # <-- We need sufficient training data, so expirement with larger training data sizes here\n",
    "    a = random.randint(0, 1)\n",
    "    b = random.randint(0, 1)\n",
    "    c = (a and b)\n",
    "    X1_train.append([a, b])\n",
    "    y1_train.append(c)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "ptron = Perceptron()\n",
    "ptron.fit(X1_train,y1_train)\n",
    "\n",
    "print(\"Building Test data...\")\n",
    "for i in range(100):\n",
    "    a = random.randint(0, 1)\n",
    "    b = random.randint(0, 1)\n",
    "    c = (a and b)\n",
    "    X1_test.append([a, b])\n",
    "    y1_test.append(c)\n",
    "    \n",
    "print(\"Results...\")\n",
    "train_error = MSE(y1_train, ptron.predict(X1_train))\n",
    "results = ptron.predict(X1_test)\n",
    "test_error = MSE(y1_test, results, squared=True)\n",
    "print(\"Overall Training Error = {:>5,.4f}\".format(train_error))\n",
    "print(\"Overall Test Error     = {:>5,.4f}\".format(test_error))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "errorTypes = [\"Test\", \"Train\"]\n",
    "wrongs = [train_error, test_error]\n",
    "rights = [(1.0 - train_error), (1.0 - test_error)]\n",
    "b1 = plt.barh(errorTypes, wrongs, color=\"orange\")\n",
    "b2 = plt.barh(errorTypes, rights, left=wrongs, color=\"blue\")\n",
    "plt.legend([b1, b2], [\"errors\", \"correct\"], title=\"Test Results\", loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505aef4-f6e1-4a12-a857-98e3703300b0",
   "metadata": {},
   "source": [
    "## Can we teach a perceptron some basic 'XOR' boolean logic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62eed8-51d6-441b-84ad-f6bbf361d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "X1_train = []\n",
    "y1_train = []\n",
    "X1_test  = []\n",
    "y1_test  = []\n",
    "\n",
    "print(\"Building Training data...\")\n",
    "for i in range(5000):                    # <-- We need sufficient training data, so expirement with larger training data sizes here\n",
    "    a = random.randint(0, 1)\n",
    "    b = random.randint(0, 1)\n",
    "    c = (a ^ b)\n",
    "    X1_train.append([a, b])\n",
    "    y1_train.append(c)\n",
    "\n",
    "print(\"Training the model...\")\n",
    "ptron = Perceptron()\n",
    "ptron.fit(X1_train,y1_train)\n",
    "\n",
    "print(\"Building Test data...\")\n",
    "for i in range(100):\n",
    "    a = random.randint(0, 1)\n",
    "    b = random.randint(0, 1)\n",
    "    c = (a ^ b)\n",
    "    X1_test.append([a, b])\n",
    "    y1_test.append(c)\n",
    "    \n",
    "print(\"Results...\")\n",
    "train_error = MSE(y1_train, ptron.predict(X1_train))\n",
    "results = ptron.predict(X1_test)\n",
    "test_error = MSE(y1_test, results, squared=True)\n",
    "print(\"Overall Training Error = {:>5,.4f}\".format(train_error))\n",
    "print(\"Overall Test Error     = {:>5,.4f}\".format(test_error))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "errorTypes = [\"Test\", \"Train\"]\n",
    "wrongs = [train_error, test_error]\n",
    "rights = [(1.0 - train_error), (1.0 - test_error)]\n",
    "b1 = plt.barh(errorTypes, wrongs, color=\"orange\")\n",
    "b2 = plt.barh(errorTypes, rights, left=wrongs, color=\"blue\")\n",
    "plt.legend([b1, b2], [\"errors\", \"correct\"], title=\"Test Results\", loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade08c5-5ff7-4cb0-946a-0a835ee81a48",
   "metadata": {},
   "source": [
    "## What about a multi-layer perceptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf974f99-c668-4a1e-b17b-ed124a7d99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import math\n",
    "import random\n",
    "\n",
    "X1_train = []\n",
    "y1_train = []\n",
    "X1_test  = []\n",
    "y1_test  = []\n",
    "\n",
    "print(\"Building Training data...\")\n",
    "for i in range(1000):                    # <-- We need sufficient training data, so expirement with larger training data sizes here (hint: add a zero)\n",
    "    a = random.randint(0, 1)\n",
    "    b = random.randint(0, 1)\n",
    "    c = (a ^ b)\n",
    "    X1_train.append([a, b])\n",
    "    y1_train.append(c)\n",
    "#print(\"Training Data: %s\" % X1_train)\n",
    "#print(\"Training Truth: %s\" % y1_train)\n",
    "\n",
    "print(\"Creating a model base...\")\n",
    "ann = MLPRegressor(solver='adam',       # solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
    "            activation='tanh',          # activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "            learning_rate=\"constant\",   # learning_rate{‘constant’, ‘invscaling’, ‘adaptive’}, default=’constant’\n",
    "            alpha=1e-5,\n",
    "            hidden_layer_sizes=(2),\n",
    "            random_state=1,\n",
    "            max_iter=200,\n",
    "            shuffle=True,\n",
    "            momentum=0.9,\n",
    "            verbose=False\n",
    "            )\n",
    "\n",
    "print(\"Training the model...\")\n",
    "ann.fit(X1_train,y1_train)\n",
    "\n",
    "print(\"Building Test data...\")\n",
    "for i in range(100):\n",
    "    a = random.randint(0, 1)\n",
    "    b = random.randint(0, 1)\n",
    "    c = (a ^ b)\n",
    "    X1_test.append([a, b])\n",
    "    y1_test.append(c)\n",
    "\n",
    "print(\"Results...\")\n",
    "train_error = MSE(y1_train, ann.predict(X1_train))\n",
    "results = ann.predict(X1_test)\n",
    "test_error = MSE(y1_test, results, squared=True)\n",
    "print(\"Overall Training Error = {:>5,.4f}\".format(train_error))\n",
    "print(\"Overall Test Error     = {:>5,.4f}\".format(test_error))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "errorTypes = [\"Test\", \"Train\"]\n",
    "wrongs = [train_error, test_error]\n",
    "rights = [(1.0 - train_error), (1.0 - test_error)]\n",
    "b1 = plt.barh(errorTypes, wrongs, color=\"orange\")\n",
    "b2 = plt.barh(errorTypes, rights, left=wrongs, color=\"blue\")\n",
    "plt.legend([b1, b2], [\"errors\", \"correct\"], title=\"Test Results\", loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b0402-5aa0-47f8-8159-65c4d96a8bf6",
   "metadata": {},
   "source": [
    "## How about some fundamental math?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5cb47-36fd-47cd-8e4e-0270e6e18818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_percentage_error as PERERR\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "#### Pythagorean Theorem (a^2 + b^2 = c^2)\n",
    "X1_train = []\n",
    "y1_train = []\n",
    "X1_test  = []\n",
    "y1_test  = []\n",
    "\n",
    "print(\"Building Training data...\")\n",
    "for i in range(50000):\n",
    "    a = random.random() * 1000\n",
    "    b = random.random() * 1000\n",
    "    c = math.sqrt(a*a + b*b)    # Pythagorean Theorem\n",
    "    X1_train.append([a, b])\n",
    "    y1_train.append(c)\n",
    "#print(\"Training Data: %s\" % X1_train)\n",
    "#print(\"Training Truth: %s\" % y1_train)\n",
    "\n",
    "print(\"Creating a model base...\")\n",
    "ann = MLPRegressor(solver='adam',       # solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
    "            activation='relu',          # activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "            learning_rate=\"constant\",   # learning_rate{‘constant’, ‘invscaling’, ‘adaptive’}, default=’constant’\n",
    "            alpha=1e-5,\n",
    "            hidden_layer_sizes=(20,15,2,15,20),\n",
    "            random_state=1,\n",
    "            max_iter=500,\n",
    "            shuffle=True,\n",
    "            momentum=0.9,\n",
    "            verbose=False\n",
    "            )\n",
    "\n",
    "print(\"Training the model...\")\n",
    "ann.fit(X1_train,y1_train)\n",
    "\n",
    "print(\"Building Test data...\")\n",
    "for i in range(100):\n",
    "    a = random.random() * 1000          # <-- Consider the magnitude of the domain/range here and how that might effect the error calculation...\n",
    "    b = random.random() * 1000\n",
    "    c = math.sqrt(a*a + b*b)    # Pythagorean Theorem\n",
    "    X1_test.append([a, b])\n",
    "    y1_test.append(c)\n",
    "\n",
    "print(\"Results...\")\n",
    "\n",
    "results = ann.predict(X1_test)\n",
    "\n",
    "test_error = MSE(y1_test, results, squared=True)\n",
    "#test_error = PERERR(y1_test, results, squared=True)\n",
    "\n",
    "train_error = MSE(y1_train, ann.predict(X1_train))\n",
    "#train_error = PERERR(y1_train, ann.predict(X1_train))\n",
    "\n",
    "print(\"Overall Training Error = %s\" % train_error)\n",
    "print(\"Overall Test Error     = %s\" % test_error)\n",
    "print(\"IF a=3 and b=4, then c=  %s\" % ann.predict([[3,4]]))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "errorTypes = [\"Test\", \"Train\"]\n",
    "wrongs = [train_error, test_error]\n",
    "rights = [(1.0 - train_error), (1.0 - test_error)]\n",
    "b1 = plt.barh(errorTypes, wrongs, color=\"orange\")\n",
    "b2 = plt.barh(errorTypes, rights, left=wrongs, color=\"blue\")\n",
    "plt.legend([b1, b2], [\"errors\", \"correct\"], title=\"Test Results\", loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeede2b2-da7c-44e0-b22a-b8824e53797b",
   "metadata": {},
   "source": [
    "## What about a function we don't know how to write necessarily?\n",
    "\n",
    "Pop quiz: without using a lookup table or a Trigonometric Identity, how do you compute the tangent function (i.e., tan(angle))? \n",
    "... unless you have an advanced degree in mathematics (or are a true math nerd), you probably don't know... but can we still teach a neural network?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ea573-d50d-4eda-a6e7-03fa303869f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "X1_train = []\n",
    "y1_train = []\n",
    "X1_test  = []\n",
    "y1_test  = []\n",
    "\n",
    "print(\"Building Training data...\")\n",
    "for i in range(5000):\n",
    "    a = random.random() * 2 * 3.141592\n",
    "    b = 1\n",
    "    c = math.tan(a)                     # Tangent Funtion\n",
    "    X1_train.append([a, b])\n",
    "    y1_train.append(c)\n",
    "#print(\"Training Data: %s\" % X1_train)\n",
    "#print(\"Training Truth: %s\" % y1_train)\n",
    "\n",
    "print(\"Creating a model base...\")\n",
    "ann = MLPRegressor(solver='adam',       # solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
    "            activation='tanh',          # activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "            learning_rate=\"constant\",   # learning_rate{‘constant’, ‘invscaling’, ‘adaptive’}, default=’constant’\n",
    "            alpha=1e-5,\n",
    "            hidden_layer_sizes=(50,50),\n",
    "            random_state=1,\n",
    "            max_iter=200,\n",
    "            shuffle=True,\n",
    "            momentum=0.9,\n",
    "            verbose=False\n",
    "            )\n",
    "\n",
    "print(\"Training the model...\")\n",
    "ann.fit(X1_train,y1_train)\n",
    "\n",
    "print(\"Building Test data...\")\n",
    "for i in range(100):\n",
    "    a = random.random() * 2 * 3.141592\n",
    "    b = 1\n",
    "    c = math.tan(a)                     # Tangent Funtion\n",
    "    X1_test.append([a, b])\n",
    "    y1_test.append(c)\n",
    "\n",
    "print(\"Results...\")\n",
    "train_error = MSE(y1_train, ann.predict(X1_train))\n",
    "results = ann.predict(X1_test)\n",
    "test_error = MSE(y1_test, results, squared=True)\n",
    "print(\"Overall Training Error = %s\" % train_error)\n",
    "print(\"Overall Test Error     = %s\" % test_error)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "errorTypes = [\"Test\", \"Train\"]\n",
    "wrongs = [train_error, test_error]\n",
    "rights = [(1.0 - train_error), (1.0 - test_error)]\n",
    "b1 = plt.barh(errorTypes, wrongs, color=\"orange\")\n",
    "b2 = plt.barh(errorTypes, rights, left=wrongs, color=\"blue\")\n",
    "plt.legend([b1, b2], [\"errors\", \"correct\"], title=\"Test Results\", loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x = np.linspace(-2 * np.pi, 2 * np.pi, 100)\n",
    "fx = np.tan(x)\n",
    "hx = [ann.predict([i, 1])[0] for i in x]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, fx, color='b', label='f(x)')\n",
    "ax.plot(x, hx, color='g', label='h(x)')\n",
    "plt.gcf().set_size_inches(15,10)\n",
    "plt.title(\"True vs NN tan(x)\")\n",
    "plt.grid(True, which='both')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435c29e-c9aa-4365-9de2-2dcbd3afd875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
