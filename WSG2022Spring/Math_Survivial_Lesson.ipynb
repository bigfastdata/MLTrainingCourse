{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Crash Course on Surviving the Math\nWeek of July 25, 2022\n\n## First, a Minimal Intro to Python","metadata":{"tags":[]},"id":"d1d189ab-5e1e-4c8d-b9d3-1f97d062ffae"},{"cell_type":"code","source":"# This is a Python Commentm which starts with a '#' sign\n# Below is Python Code\n\nmyValue = 234.234\nmyVector = [1, 1, 2, 3, 5, 8, 13]\n\n# Uniform random between 0.0-1.0\nrandX = random.random()\n# random.gauss(mu, sigma)\n# random.uniform(a, b)\n# random.paretovariate(alpha)\n# random.weibullvariate(alpha, beta)\n\nprint(\"My scalar value is %s\" % myValue)\nprint(\"My vector has the list of values: %s\" % myVector)","metadata":{},"execution_count":1,"outputs":[{"name":"stdout","text":"My scalar value is 234.234\nMy vector has the list of values: [1, 1, 2, 3, 5, 8, 13]\n","output_type":"stream"}],"id":"6b01370e-5035-4309-9599-5793dbb2072d"},{"cell_type":"markdown","source":"## Chapter 4 - Linear Algebra\n\n### The Second Most Imporant Equation in Machine Learning\n\nThere are [may different 'distance' approaches](https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa), but the most common is one we are familiar with by other names and simpler forms:\n\n![Euclidian Distance](https://miro.medium.com/max/844/0*wv6oFAVd0_PQ50mX)\n\n... but in the end, these are all forms of the [Minkowski Distance](https://en.wikipedia.org/wiki/Minkowski_distance): \n\n![Minkowski Distance](https://miro.medium.com/max/902/0*UbbyH2MUPb5ZBa64)\n\n\nThe value of 'p' transforms the equation from Manhattan distance (p=0, a.k.a. L1-Norm) to Euclidian distance (p=1, a.k.a. L2-Norm), or [Chebyshev distance](https://en.wikipedia.org/wiki/Chebyshev_distance) as p approaches infinitiy. For fractional values of 'p' where 0 < p < 1, the 'Agrawal' distance is extremely useful to mitigate the [Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). \n\n![Variations of P](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/2D_unit_balls.svg/967px-2D_unit_balls.svg.png)\n\n### In Python","metadata":{},"id":"a7a99423-e402-4f6f-a51c-9f8f66863728"},{"cell_type":"code","source":"import random\n\nN = 3\nvec0 = [0 for x in range(N)] \nvec1 = [random.randint(1, 5) for x in range(N)] \nvec2 = [random.gauss(3, 2) for x in range(N)] \nvec1.sort()\nvec2.sort()\nprint(\"Vector 0: %s\" % vec0)\nprint(\"Vector 1: %s\" % vec1)\nprint(\"Vector 2: %s\" % vec2)\n\ndef minkowski(a, b, p):\n    result = 0\n    if len(a) == len(b):\n        summation = 0\n        for i in range(len(a)):\n            d = abs(a[i] - b[i])\n            summation += pow(d,p)\n        result = pow(summation,1.0/p)\n    else:\n        print(\"WARNING: array sizes must be the same!\")\n    return result\n\nprint(\"L1-Norm of Vec1:    {:>10,.2f}\".format(minkowski(vec0, vec1, 1)))\nprint(\"L2-Norm of Vec1:    {:>10,.2f}\".format(minkowski(vec0, vec1, 2)))\nprint(\"L1-Norm of Vec2:    {:>10,.2f}\".format(minkowski(vec0, vec2, 1)))\nprint(\"L2-Norm of Vec2:    {:>10,.2f}\".format(minkowski(vec0, vec2, 2)))\nprint(\"Agrawal   Distance: {:>10,.2f}\".format(minkowski(vec1, vec2, 0.1)))\nprint(\"Manhattan Distance: {:>10,.2f}\".format(minkowski(vec1, vec2, 1)))\nprint(\"Euclidian Distance: {:>10,.2f}\".format(minkowski(vec1, vec2, 2)))\nprint(\"Chebyshev Distance: {:>10,.2f}\".format(minkowski(vec1, vec2, 100)))","metadata":{"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Vector 0: [0, 0, 0]\nVector 1: [1, 2, 5]\nVector 2: [0.566876228727669, 1.3329333675747215, 1.6597717531115945]\nL1-Norm of Vec1:          8.00\nL2-Norm of Vec1:          5.48\nL1-Norm of Vec2:          3.56\nL2-Norm of Vec2:          2.20\nAgrawal   Distance:  60,689.43\nManhattan Distance:       4.44\nEuclidian Distance:       3.43\nChebyshev Distance:       3.34\n","output_type":"stream"}],"id":"850ee313-e74c-4434-88ce-e3361e40240c"},{"cell_type":"markdown","source":"## Chapter 5 - Statistics\n\n\n### Continuous Probability Distributions\n\n\n### Discrete Probability Distributions\n\n\n### Statistics and Randomness in Python\n\n","metadata":{},"id":"3375b9e0-9f20-4af9-bfd6-9ebb2fad3b60"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"6139c465-752c-4bd6-8b32-b05e97019b6e"},{"cell_type":"markdown","source":"## Chapter 6 - Probability\n\n### Joint Probability\n\n### Priors\n\n### Bayes Formula (or the Third Most Important Formula in Machine Learning)\nDevised by Thomas Bayes in the 1700's, but now a critical for predictive modeling and analysis:\n\n![Bayes Formula](https://wikimedia.org/api/rest_v1/media/math/render/svg/c1a7279a1639d92d751e0f2d3aa54e62a2ddb1e8)\n\nThe common formulation and use deals with seemingly likely outcomes weighted by other information:\n\n![BayesUse](https://wikimedia.org/api/rest_v1/media/math/render/svg/b01f679001d8f19c6c6036f1ac66ca3c3f400258)\n\n### The Monte Hall Problem\nImagine you are at a game show, with three doors. One has a good prize, two have a bad prize (goat?). You choose one:\n\n![Monte Hall Step 1](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/220px-Monty_open_door.svg.png)\n\nThen the host reveals one door with two assumptions:\n\n1) The Host will NOT reveal the door you chose first\n2) The Host will NOT reveal the prize\n\nThe host then asks if you want to keep your original door choice, or switch to the remaining door. This is your final choice and you will get the prize (or goat) behind your final decision. What choice should you make to maximize your probability of winning the prize?\n\n![Monte Hall Step 2](https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Monty_Hall_Problem_-_Standard_probabilities.svg/330px-Monty_Hall_Problem_-_Standard_probabilities.svg.png)\n\nLet's prove the Monte Hall solution using Monte Carlo (no relation):","metadata":{},"id":"2f5ebf2f-357f-4162-8fdd-bea1dd0e0ca0"},{"cell_type":"code","source":"import random\n\n# Let D = number of doors in the game\nD=3\n\n# Let us run these many trials (large number for sufficient statistics)\nTRIALS=10\n\n# These will be our two strategies\nSWITCH_STRATEGY=True\nSTAY_STRATEGY=False\n\n# Define a single instance/execution of the game\ndef monteHallGame(strategy):\n    # Create D Doors\n    door_list = [x+1 for x in range(D)]\n    # Place the Prize\n    door_with_prize = random.randint(1, D)\n    # Choose first door\n    door_I_choose  = random.randint(1, D)\n    # Remove all but two doors keeping with the rules of the game\n    remaining_doors_list = [door_I_choose]\n    if door_I_choose == door_with_prize:\n        remaining_doors_list.append(random.randint(1, D))\n    else:\n        remaining_doors_list.append(door_with_prize)\n        \n    if strategy == SWITCH_STRATEGY: \n        # If switching, remove my door from choices\n        remaining_doors_list.remove(door_I_choose)\n        # Then my final choice is the remaining door\n        door_I_choose = remaining_doors_list[0] \n                \n    # return True (1) if we chose the prize\n    return door_with_prize == door_I_choose\n\n# Manage multiple independant expirements of the game\ndef monteCarlo(strategy):\n    winCount = 0\n    for i in range(TRIALS):\n        winCount += monteHallGame(strategy) \n    return winCount\n\n\nswitch_wins = monteCarlo(SWITCH_STRATEGY)\nstay_wins   = monteCarlo(STAY_STRATEGY)\n\nprint('Results with %s doors and %s trials' % (D,TRIALS))\nprint('Proportion of wins without switching: {:.2f}%'.format(100.0*stay_wins/TRIALS))\nprint('Proportion of wins with switching: {:.2f}%'.format(100.0*switch_wins/TRIALS))","metadata":{},"execution_count":4,"outputs":[{"name":"stdout","text":"Results with 1000 doors and 5000 trials\nProportion of wins without switching: 0.06%\nProportion of wins with switching: 99.86%\n","output_type":"stream"}],"id":"61d11853-b944-44ab-96f2-7aa1c14b62f2"},{"cell_type":"markdown","source":"... but if you still don't believe it, here are some different perspectives:\n\n* From the movie '21': ['21' Movie depiction of Monte Hall](https://youtu.be/iBdjqtR2iK4)\n* My favorite [explination by Numberphile](https://youtu.be/4Lb-6rxZxx0)\n* A less mathmatical by very historical view [as explained by Vox](https://youtu.be/ggDQXlinbME)\n* An entertaining [explination by VSauce](https://youtu.be/TVq2ivVpZgQ) ... this guy is weird.","metadata":{},"id":"d42887d9-0a14-42e3-a9ef-dc31579f1ff1"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"0051eb04-ab25-4a78-b9b5-8224055cc8a0"}]}